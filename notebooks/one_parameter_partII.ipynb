{
 "metadata": {
  "name": "one_parameter_partII"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Probabilistic results"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Chernoff bound"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "\n",
      "\n",
      "The simplest result for bounding the tail probability of the\n",
      "sufficient statistic is Chernoff's bound, based on\n",
      "Markov's inequality and the cumulant generating function."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "For every $s \\geq 0$ and $u \\geq \\Ee_{\\eta}(t(X))$ we have\n",
      "$$\n",
      "\\begin{aligned}\n",
      "\\Pp_{\\eta}(t(X) \\geq u) &\\leq \\frac{\\Ee_{\\eta}(e^{s \\cdot t(X)})}{e^{su}} \\\\\n",
      "&= \\Ee_{\\eta}(e^{s \\cdot t(X) - su}) \\\\\n",
      "&= \\exp \\left(\\CGF(s+\\eta) - su - \\CGF(\\eta) \\right) \\\\\n",
      "&= \\exp \\left(\\tilde{\\CGF}_{\\eta}(s) - su \\right) \\\\\n",
      "\\end{aligned}\n",
      "$$\n",
      "where $$\\tilde{\\CGF}_{\\eta}(s)=\\CGF(\\eta+s)-\\CGF(s)$$ is the cumulant generating function of $t(X)$ under $\\Pp_{\\eta}$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Optimizing over $s$ yields\n",
      "$$\n",
      "\\begin{aligned}\n",
      "\\Pp_{\\eta}(t(X) \\geq u) &\\leq \\exp \\left(-\\sup_{s \\geq 0} \\left[us - \\tilde{\\CGF}_{\\eta}(s)\\right] \\right) \\\\\n",
      "&= \\exp(-\\tilde{\\CGF}^*_{\\eta}(u)).\n",
      "\\end{aligned}\n",
      "$$\n",
      "In the transition from the second to the third line above we have implicitly assumed that \n",
      "$$\n",
      "\\begin{aligned}\n",
      "\\tilde{\\CGF}^*_{\\eta}(u) &= \\sup_{s} \\left[us - \\tilde{\\CGF}_{\\eta}(s)\\right] \\\\\n",
      "&= \\sup_{s \\geq 0} \\left[us - \\tilde{\\CGF}_{\\eta}(s)\\right].\n",
      "\\end{aligned}\n",
      "$$\n",
      "That is, we assumed that the supremum was achieved at a positive $s$. This follows from the fact that in order to tilt $\\Pp_{\\eta}$ to have mean $u > \\Ee_{\\eta}(t(X))$ we must tilt with a positive exponent. This also follows from monotonicity of the mapping $\\eta \\mapsto \\mu(\\eta)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Recall that\n",
      "$\\dot{\\CGF}^*_{\\eta}(u)$ can be interpreted as the $s=s(u)$ chosen so that\n",
      "$$\n",
      "\\Ee_{\\eta+s}(t(X))=u.\n",
      "$$\n",
      "The quantity $\\tilde{\\CGF}^*_{\\eta}$ can be thought of as the *cost* of tilting \n",
      "$\\Pp_{\\eta}$ so that it has mean $\\mu$. \n",
      "\n",
      "Chernoff's bound therefore says that\n",
      "the probability that $t(X) > u$ under $\\Pp_{\\eta}$ is exponential in the cost of tilting\n",
      "$\\Pp_{\\eta}$ to have mean $u$.\n",
      "\n",
      "There is a corresponding lower version of Chernoff's bound. For any $u < \\Ee_{\\eta}(t(X))$\n",
      "$$\n",
      "\\begin{aligned}\n",
      "\\Pp_{\\eta}(t(X) < u) & \\leq \\exp \\left(-\\sup_{s \\leq 0} su - \\CGF_{\\eta}(s) \\right) \\\\\n",
      "&= \\exp(-\\CGF^*_{\\eta}(u)).\n",
      "\\end{aligned}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "exercise": {
       "number": "2"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### *Exercise: Poisson Chernoff bound*\n",
      "\n",
      "Suppose $X \\sim \\text{Poisson}(\\lambda)$. \n",
      "\n",
      "1. Compute $\\CGF^*(\\mu)$ with $\\CGF$ the cumulant generating function of $X$ (i.e.\n",
      "consider the Poisson family to have carrier measure $\\text{Poisson}(\\lambda)$). \n",
      "\n",
      "2. For $\\lambda=4$, compute the Chernoff bound for \n",
      "$$\n",
      "\\Pp(X > 10).\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "exercise": {
       "number": "2"
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "### *Exercise: exponential Chernoff bound*\n",
      "\n",
      "Suppose $X \\sim \\text{Exponential}(\\lambda)$. \n",
      "\n",
      "1. Compute $\\CGF^*(\\mu)$  with $\\CGF$ the cumulant generating function of $X$. \n",
      "\n",
      "2. For $\\lambda=4$, compute the Chernoff bound for \n",
      "$$\n",
      "\\Pp(X > 10).\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Saddle point approximation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "The saddle point approximation is an approximation for the density of \n",
      "$\\overline{t(X)}$  having observed an IID sample of size $n$ under $\\Pp_{\\eta}$.\n",
      "\n",
      "The approximation is\n",
      "$$\n",
      "\\begin{aligned}\n",
      "f_{\\overline{t(X)}}(t) &\\approx \n",
      " \\left(2 \\pi \\Vv_{\\eta(t)}(\\overline{t(X)})\\right)^{-1/2} e^{-\\sup_{s} \\left[ts-n\\CGF_{\\eta}(s/n) \\right]} \\\\\n",
      "&= \\left(2 \\pi \\Vv_{\\eta(t)}(\\overline{t(X)})\\right)^{-1/2} e^{-\\CGF^{n \\, *}_{\\eta}(t)} \\\\\n",
      "\\end{aligned}\n",
      "$$\n",
      "where\n",
      "$$\n",
      "\\CGF^n_{\\eta}(s) = \\Ee_{\\eta}(e^{s \\overline{t(X)}}) = n\\CGF_{\\eta}(s/n) = n \\left[\\CGF(\\eta+s/n) - \\CGF(\\eta)\\right]\n",
      "$$\n",
      "is the CGF of $\\overline{t(X)}$ under $\\Pp_{\\eta}$.\n",
      "\n",
      "In short,\n",
      "$$\n",
      "\\CGF^{n \\, *}_{\\eta}(t) = n \\CGF^*_{\\eta}(t)\n",
      "$$\n",
      "is the cost needed to tilt $\\overline{t(X)}$ to have mean $t$. The multiplier in front\n",
      "is a term that comes up from the fact that, after tilting $\\overline{t(X)}$ to have mean\n",
      "$t$, the quantity $\\overline{t(X)}-t$ is roughly normally distributed under\n",
      "the new distribution.\n",
      "\n",
      "See, for example [Explaining the Saddlepoint Approximation](http://www.jstor.org/stable/2686100).\n",
      "\n",
      "One simple way to think of the saddlepoint approximation for the density at some point $t$ for any one parameter exponential family is:\n",
      "    \n",
      "1. The exponential part is the cost it takes to tilt the family to have mean $t$.\n",
      "    \n",
      "2. The premultiplier is the implied variance of the local CLT after tilting."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "exercise": {
       "number": "2"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### *Exercise*\n",
      "\n",
      "1. Show that\n",
      "$$\n",
      "\\CGF^{n \\, *}_{\\eta}(t) = n \\CGF^*_{\\eta}(t).\n",
      "$$\n",
      "\n",
      "2. Show that \n",
      "$$\n",
      "n \\CGF^*_{\\eta}(t) = \\tilde{D}^n(t;\\Ee_{\\eta}(t(X)))/2.\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "exercise": {
       "number": "2"
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "### *Exercise: Gamma density*\n",
      "\n",
      "1. Compute the saddlepoint approximation to the Gamma density with shape parameter 5 and scale parameter 1 at some fixed $t$.\n",
      "\n",
      "2. Plot your approximation.\n",
      "\n",
      "3. Repeat for shape parameter 12.3."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Subgaussianity"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "A common condition seen in many high-dimensional statistics problems these days\n",
      "is *subgaussianity*. A random variable $Z$ is *subgaussian* with scale factor\n",
      "$\\sigma > 0$, \n",
      "$$\n",
      "\\Ee(\\exp(tZ)) \\leq e^{t^2 \\sigma^2/2}.\n",
      "$$\n",
      "\n",
      "Exponential families all satisfy a local form of this property. Specifically, set\n",
      "$$\n",
      "Z = t(X) - \\Ee_{\\eta}(t(X)).\n",
      "$$\n",
      "Then, as long as $t+\\eta \\in \\D(\\F)$\n",
      "$$\n",
      "\\begin{aligned}\n",
      "\\Ee_{\\eta}(\\exp^{tZ}) &= \\exp \\left(\\CGF(t+\\eta)-\\CGF(\\eta)- t \\dot{\\CGF}(\\eta) \\right) \\\\\n",
      "& \\leq \\exp\\left(\\frac{t^2}{2} C(t,\\eta) \\right)\n",
      "\\end{aligned}\n",
      "$$\n",
      "where\n",
      "$$\n",
      "C(t,\\eta) = \\sup_{|r|<t} \\ddot{\\CGF}(\\eta+r)\n",
      "$$\n",
      "is a local bound on $\\Vv_{\\eta}(t(X))$. \n",
      "\n",
      "In particular, if \n",
      "$$\n",
      "\\sup_{\\eta \\in \\D(\\F)} \\Vv_{\\eta}(t(X)) = C_2 < \\infty.\n",
      "$$\n",
      "\n",
      "Then, $t(X)-\\Ee_{\\eta}(t(X))$ is subgaussian with scale factor $\\sqrt{C_2}$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "exercise": {
       "number": "2"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### *Exercise: subgaussianity*\n",
      "\n",
      "1. Give an example of a one parameter exponential family that is subgaussian.\n",
      "\n",
      "2. Give an example of a one parameter exponential family that is not subgaussian."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Bayesian models and exponential families"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Suppose we observe $Y=y$ from the exponential family\n",
      "$$\n",
      "\\Pp_{\\eta}(dy) = e^{\\eta \\cdot y - \\CGF(\\eta)} m_0(dy)\n",
      "$$\n",
      "and we assume that $\\eta$ has a prior density\n",
      "$\\pi(\\eta)$ with respect to Lebesgue measure on $\\real$.\n",
      "\n",
      "Then, the posterior density is\n",
      "$$\n",
      "\\pi(\\eta|y) \\; d\\eta= \\frac{\\pi(\\eta) \\cdot e^{\\eta \\cdot y-\\CGF(\\eta)} \\; d\\eta}{\\int_{\\real} \\pi(\\zeta) \\cdot e^{\\zeta y-\\CGF(\\zeta)} \\; d\\zeta}.\n",
      "$$\n",
      "\n",
      "Or,\n",
      "$$\n",
      "\\pi(\\eta|y) \\; d\\eta= \\exp \\left(\\eta \\cdot y- \\log \\left(\\int_{\\real} \\pi(\\zeta) \\cdot e^{\\zeta \\cdot y-\\CGF(\\zeta)} \\; d\\zeta \\right) \\right) \\cdot \\pi(\\eta) e^{-\\CGF(\\eta)}.\n",
      "$$\n",
      "\n",
      "This is in fact a one-parameter exponential family of distributions on $\\real$ where:\n",
      "\n",
      "1. The natural parameter is $y$.\n",
      "\n",
      "2. The reference or carrier measure is $\\pi(\\eta) e^{-\\CGF(\\eta)} \\; d\\eta$.\n",
      "\n",
      "3. The cumulant generating function is \n",
      "$$\n",
      "\\log \\left(\\int_{\\real} \\pi(\\zeta) \\cdot e^{\\zeta \\cdot y-\\CGF(\\zeta)} \\; d\\zeta \\right).\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "exercise": {
       "number": "2"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### *Exercise*\n",
      "\n",
      "As $\\mu=\\dot{\\CGF}(\\eta)$, we can also work out the posterior density of $\\mu$:\n",
      "$$\n",
      "\\begin{aligned}\n",
      "\\pi(\\mu|y)  &= \\pi(\\eta(\\mu)|y) \\frac{d\\eta(\\mu)}{d\\mu} \\\\\n",
      "&= \\frac{\\pi(\\eta(\\mu)|y) }{\\Vv_{\\eta}(Y)} \\\\\n",
      "\\end{aligned}\n",
      "$$\n",
      "\n",
      "1. What is the natural parameter for the exponential family $\\pi(\\mu|y)$?\n",
      "\n",
      "2. What is the reference measure for the exponential family $\\pi(\\mu|y)$?"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Conjugate priors"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "For a given exponential family, certain families of priors are particularly convenient. \n",
      "They are convenient in the sense that\n",
      "the posterior density, or distribution is in the same family of distributions.\n",
      "\n",
      "For example, suppose our exponential family is the $\\text{Binomial}(m,p)$ family\n",
      "$$\n",
      "\\Pp_{\\eta} (j) = \\exp \\left(j \\eta - m \\cdot \\log(1 + e^{\\eta}) \\right) dm_0(j)\n",
      "$$\n",
      "\n",
      "In terms of the probability parameterization $p =  e^{\\eta} / (1 + e^{\\eta})$ this reads as\n",
      "$$\n",
      "\\Pp_{p}(y) = \\exp \\left(y \\log(p/(1-p)) + m \\cdot \\log(1 - p) \\right).\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Now, suppose we take a $\\text{Beta}(\\alpha,\\beta)$ distribution as prior\n",
      "$$\n",
      "\\pi(p) \\; dp = \\left(B(\\alpha, \\beta)\\right)^{-1} p^{\\alpha-1} (1-p)^{\\beta-1} 1_{(0,1)}(p) \\; dp\n",
      "$$\n",
      "(This is an example of a two-parameter exponential family $\\dots$)\n",
      "\n",
      "Then, we see\n",
      "$$\n",
      "\\begin{aligned}\n",
      "\\pi(p|y) \\propto \\exp \\left((y+\\alpha-1) \\log p + (m-y+\\beta-1) \\log (1-p) \\right)\n",
      "\\end{aligned}\n",
      "$$\n",
      "which is of course the $\\text{Beta}(\\alpha+y,\\beta+m-y)$ distribution."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "exercise": {
       "number": "2"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### *Exercise: Poisson / Gamma family*\n",
      "\n",
      "Suppose $Y \\sim \\text{Poisson}(\\mu)$ and we place a Gamma prior on $\\mu$ with density\n",
      "$$\n",
      "\\pi(\\mu)  = \\frac{1}{\\Gamma(k) \\theta^k} \\mu^{k-1} e^{-\\mu/\\theta} 1_{[0,\\infty)}(\\mu) = \\text{Gamma}(k, \\theta).\n",
      "$$ \n",
      "\n",
      "1. Show that\n",
      "$$\n",
      "\\pi(\\mu|y) = \\text{Gamma}\\left(y+k, \\frac{\\theta}{\\theta+1}\\right).\n",
      "$$\n",
      "\n",
      "2. What is the posterior distribution of $\\mu$ having observed $Y_1, \\dots, Y_n | \\mu \\overset{IID}{\\sim} \\text{Poisson}(\\mu)$. \n",
      "\n",
      "3. Suppose, instead, $Y_1, \\dots, Y_n \\overset{IID}{\\sim} \\text{Poisson}(\\mu_0)$ for some fixed $\\mu_0$. Can you make sense of the density $\\pi(\\mu|y_1, \\dots, y_n)$? What happens to these densities as $n \\rightarrow \\infty$ (you may have to rescale and center)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "General form"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "For this general relationship, called *conjugacy* to work, it's clear that the\n",
      "prior must  be related to $\\CGF(\\eta)$. Suppose our prior is an exponential family\n",
      "with sufficient statistic $\\eta$ and natural parameter $\\omega$\n",
      "$$\n",
      "\\pi(\\eta) d\\eta = e^{\\omega \\cdot \\eta - \\Theta(\\eta)} \\; d\\eta.\n",
      "$$\n",
      "\n",
      "Then, the posterior is proportional to\n",
      "$$\n",
      "\\exp \\left( (y + \\omega) \\cdot \\eta - \\CGF(\\eta) - \\Theta(\\eta) \\right).\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "If we had set $\\Theta=\\CGF$ our posterior would be proportional to\n",
      "$$\n",
      "\\exp((y+\\omega)\\eta - 2\\CGF(\\eta))\n",
      "$$\n",
      "and would be in the family\n",
      "$$\n",
      "\\exp(\\alpha(\\omega \\cdot \\eta - \\CGF(\\eta))).\n",
      "$$\n",
      "This is our first example of a two-parameter family (it is the same as the Beta-Binomial).\n",
      "\n",
      "This leads us to the general form for the conjugate priors:\n",
      "$$\n",
      "\\pi(\\eta) \\; d\\eta = e^{\\alpha \\left[\\omega \\cdot \\eta - \\CGF(\\eta) \\right]} \\; d\\eta\n",
      "$$\n",
      "with posterior\n",
      "$$\n",
      "\\pi(\\eta|y) \\propto \\exp\\left( \\left(\\alpha \\omega + y \\right)\\cdot \\eta - (\\alpha + 1) \\CGF(\\eta) \\right)\n",
      "$$\n",
      "\n",
      "See [Conjugate Priors for Exponential Families](http://projecteuclid.org/euclid.aos/1176344611)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "exercise": {
       "number": "2"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### *Exercise: conjugate priors for repeated sampling*\n",
      "\n",
      "1. Above, we worked out the posterior for $\\eta$ in the $(\\alpha, \\omega)$ family of conjugate priors\n",
      "$$\n",
      "\\exp(\\alpha(\\omega \\cdot \\eta - \\CGF(\\eta)))\n",
      "$$\n",
      "Write the parameters of $\\pi(\\eta|y)$ in terms of new $(\\alpha, \\omega)$. \n",
      "\n",
      "2. Repeat the above for having observed $Y_1, \\dots, Y_n | \\eta \\overset{IID}{\\sim} \\Pp_{\\eta}$ where $\\pi(\\eta) d\\eta = \\exp(\\alpha(\\omega \\cdot \\eta - \\CGF(\\eta))) d\\eta$.\n",
      "\n",
      "3. Suppose that instead $Y_1, \\dots, Y_n \\overset{IID}{\\sim} \\Pp_{\\eta_0}$ for some fixed $\\eta_0$. What do you expect will happen (as $n \\rightarrow \\infty$) to the sequence of densities \n",
      "$$\n",
      "\\pi(\\eta|y_1, \\dots, y_n)?\n",
      "$$"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Tweedie's formula"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this section, we cover just some of the material from [Tweedie's formula and selection bias](http://www.tandfonline.com/doi/abs/10.1198/jasa.2011.tm11181).\n",
      "                                                          \n",
      "We suppose that $\\eta$ has prior density $\\pi(\\eta)$ with respect to some measure and we observe \n",
      "$$\n",
      "Y|\\eta \\sim \\Pp_{\\eta}\n",
      "$$                    \n",
      "where \n",
      "$$\n",
      "\\Pp_{\\eta}(dy) = f_{\\eta}(y) \\; dy = e^{y\\cdot \\eta - \\CGF(\\eta)} f_0(y) \\; dy.\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "As in our earlier calculations, this leads to a one-parameter family for $\\eta$\n",
      "$$\n",
      "\\pi(\\eta|y) = \\exp \\left(y \\cdot \\eta - \\Theta(y) \\right) e^{-\\CGF(\\eta)}  \\pi(\\eta)\n",
      "$$\n",
      "where\n",
      "$$\n",
      "\\begin{aligned}\n",
      "\\Theta(y) &= \\log \\left(\\frac{\\int_{\\real} f_0(y) \\cdot e^{\\zeta \\cdot y-\\CGF(\\zeta)} \\; \\pi( d\\zeta) }{f_0(y)}\\right) \\\\\n",
      "&= \\log\\left( \\frac{f(y)}{f_0(y)} \\right)\n",
      "\\end{aligned}\n",
      "$$\n",
      "where $f$ is the marginal density of $Y$ and $f_0$ is the density of $Y$ at $\\eta=0$, i.e.\n",
      "when the prior is a point mass at 0."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Expectation and variance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Differentiating with respect to our natural parameter yields formulae for the posterior\n",
      "mean and variance of our sufficient statistic (which we recall is $\\eta$ in the posterior, while the natural parameter is $y$)\n",
      "$$\n",
      "\\begin{aligned}\n",
      "\\Ee(\\eta|y) &= \\dot{\\ell}(y) - \\dot{\\ell}_0(y)\\\\\n",
      "&= \\frac{\\dot{f}(y)}{f(y)} - \\frac{\\dot{f}_0(y)}{f_0(y)} \\\\\n",
      "\\Vv(\\eta|y) &= \\ddot{\\ell}(y) - \\ddot{\\ell}_0(y)\n",
      "\\end{aligned}\n",
      "$$\n",
      "with $\\ell(y)=\\log f(y), \\ell_0(y) = \\log f_0(y)$."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "exercise": {
       "number": "2"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### *Exercise: the normal model*\n",
      "\n",
      "Suppose $g_0(y) = \\frac{e^{-y^2/2}}{\\sqrt{2 \\pi}}$ and $t(y)=y$. That is, our family is\n",
      "$$\n",
      "\\Pp_{\\eta}(dy) = e^{\\eta \\cdot y - \\CGF(\\eta)} e^{-y^2/2} \\; dy.\n",
      "$$\n",
      "\n",
      "The `R` package `sda` contains a gene expression data set comparing healthy to patients\n",
      "with prostate cancer."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%R\n",
      "library(sda)\n",
      "data(singh2002)\n",
      "labels = singh2002$y\n",
      "print(summary(labels))\n",
      "expression_data = singh2002$x\n",
      "print(dim(expression_data))"
     ],
     "language": "python",
     "metadata": {
      "exercise": {
       "number": "2"
      },
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "display_data",
       "text": [
        "    library(sda)\n",
        "    data(singh2002)\n",
        "    labels = singh2002$y\n",
        "    print(summary(labels))\n",
        "\u0000"
       ]
      },
      {
       "output_type": "display_data",
       "text": [
        "    ##  cancer healthy \n",
        "    ##      52      50\n",
        "\u0000"
       ]
      },
      {
       "output_type": "display_data",
       "text": [
        "    expression_data = singh2002$x\n",
        "    print(dim(expression_data))\n",
        "\u0000"
       ]
      },
      {
       "output_type": "display_data",
       "text": [
        "    ## [1]  102 6033\n",
        "\u0000"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "exercise": {
       "number": "2"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "1. Compute $\\dot{\\ell}_0(y), \\ddot{\\ell}_0(y)$.\n",
      "\n",
      "2. Show that, for whatever prior one uses for $\\eta$:\n",
      "$$\n",
      "\\begin{aligned}\n",
      "\\Ee(\\eta|y) &= y + \\dot{\\ell}(y) \\\\\n",
      "\\Vv(\\eta|y) &= 1 + \\ddot{\\ell}(y).\n",
      "\\end{aligned}\n",
      "$$\n",
      "\n",
      "3. Form the 6033 two-sample $t$-statistics comparing healthy to normal, one for each gene. Using these $t$-statistics, form a density estimate and a numerical estimate of $\\dot{\\ell}$ and $\\ddot{\\ell}$. (We will see shortly a more natural way to estimate the above derivatives...)\n",
      "\n",
      "4. Of course, $t$-statistics are not normally distributed. Transform your $t$-statistics\n",
      "to $Z$ statistics using the $t$ and $N(0,1)$ distribution functions and repeat the above.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "exercise": {
       "number": "2"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### *Exercise: the Poisson model*\n",
      "\n",
      "Suppose we are in the Poisson family\n",
      "$$\n",
      "\\Pp_{\\eta}(dy) = \\exp(\\eta \\cdot y - \\CGF(\\eta)) m_0(dy).\n",
      "$$\n",
      "\n",
      "1. For a given prior $\\Pi(d\\eta)$, what is the CGF for the exponential\n",
      "family\n",
      "$$\n",
      "\\Pp(d\\eta|y)?\n",
      "$$\n",
      "\n",
      "2. Compute $\\dot{\\ell}_0(y), \\ddot{\\ell}_0(y)$. Does it matter that\n",
      "$f$, $f_0$ are not densities with respect to Lebesgue measure?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "exercise": {
       "number": "2"
      },
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### *Exercise: computing a conditional likelihood*\n",
      "\n",
      "Suppose we observe a $2 \\times 2$ contingency table when conducting a study on the efficiacy\n",
      "of a new experimental surgery for ulcers.\n",
      "\n",
      "<table>\n",
      "    <tr>\n",
      "        <td></td><td>Success</td><td>Failure</td><td>Total</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "        <td>Treatment</td><td>9</td><td>12</td><td>21</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "    <td>Control</td><td>7</td><td>17</td><td>24</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "            <td>Total</td><td>16</td><td>29</td><td>45</td>\n",
      "    </tr>\n",
      "\n",
      "</table>\n",
      "\n",
      "We would model this as $(Y_{11},Y_{12},Y_{21},Y_{22}) \\sim \\text{Multinomial}(n,(\\pi_{11}, \\pi_{12}, \\pi_{21}, \\pi_{22}))$.\n",
      "\n",
      "<table>\n",
      "    <tr>\n",
      "        <td></td><td>$A$</td><td>$A^c$</td><td>Total</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "        <td>$B$</td><td>$Y_{11}$</td><td>$Y_{12}$</td><td>$Y_{1 \\cdot}$</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "    <td>$B^c$</td><td>$Y_{21}$</td><td>$Y_{22}$</td><td>$Y_{2\\cdot}$</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "            <td>Total</td><td>$Y_{\\cdot 1}$</td><td>$Y_{\\cdot 2}$</td><td>$n$</td>\n",
      "    </tr>\n",
      "\n",
      "</table>\n",
      "\n",
      "1. Show that given $(Y_{1\\cdot}, Y_{\\cdot 1}, n)$ the only remaining \"degrees of freedom\" in determining the table is in any one of the entries, say $Y_{11}$.\n",
      "\n",
      "2. The conditional mass function $Y_{11}|Y_{1\\cdot}=m, Y_{\\cdot 1}=t$ is \n",
      "$$\n",
      "g_{\\theta}(Y_{11}) = \\binom{Y_{1 \\cdot}}{Y_{11}} \\binom{n-Y_{1 \\cdot}}{Y_{\\cdot 1}-Y_{11}} \\cdot  e^{\\theta Y_{11} - \\CGF(\\theta)}$$\n",
      "with range\n",
      "$$\n",
      "\\max(0, Y_{\\cdot 1} + Y_{1 \\cdot}-n) \\leq Y_{11} \\leq \\min(Y_{1\\cdot}, Y_{\\cdot 1})\n",
      "$$\n",
      "where\n",
      "$$\n",
      "\\theta = \\log \\left(\\frac{\\pi_{11}}{\\pi_{12}} \\bigl/{\\frac{\\pi_{21}}{\\pi_{22}}}\\right).\n",
      "$$\n",
      "How would you estimate $\\theta$ from the data?\n",
      "\n",
      "3. Numerically compute and plot the likelihood and compare its maximum value to your estimate."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}